{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9761498a",
   "metadata": {},
   "source": [
    "# Robot control systems\n",
    "\n",
    "Robots are equipped with various actuators that receive inputs and sensors that provide outputs. A robot's computer faces the task of deciding what signals to send to the actuators based on the measured sensor readings such that a robot executes desired behavior. This task of controlling the robot must address various challenges such as measurement noise, inaccurate robot models, non-ideal actuators and external disturbances. Control theory offers a systematic approach to address this challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd411f7",
   "metadata": {},
   "source": [
    "<img src=\"tp3/media/system.png\" alt=\"A system\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a654b",
   "metadata": {},
   "source": [
    "\n",
    "A robot can be modelled as a _system_ taking inputs $u_k$ and producing outputs $y_k$, where $k \\in \\mathbb{Z}$ is the discrete time index. We will consider discrete-time systems throughout this assignment. Continuous-time systems can be well approximated by discrete-time systems via numerical integration methods, such as Euler integration or Runge-Kutta methods.\n",
    "\n",
    "Let us start with a simple, yet widely-applicable class of systems, namely a discrete-time linear time invariant (LTI) system. It can be expressed the the so-called state-space form as follows\n",
    "\n",
    "$x_{k+1} = Ax_k + Bu_k$,\n",
    "\n",
    "and the output is also given by a linear equation\n",
    "\n",
    "$y_k = Cx_k + Du_k$.\n",
    "\n",
    "The matrix $D = 0$ most often in practice. The system is called linear because the system dynamics is linear in $x$ and $u$, the input-output relationship is affine, and time-invariant because the dynamics parameters $A, B, C$, and $D$ are assumed to not depend on time. Moreover, if the system is fully-observed, i.e., all of its states are measured: $C = I$.\n",
    "\n",
    "#### Pure Feedforward Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3aae18",
   "metadata": {},
   "source": [
    "Suppose that we have a $y_{\\mathrm{des},k}$ be a discrete-time desired output trajectory for our system. One of the simplest controllers that can we can develop to execute this task is an `open-loop' feedforward controller, whose schematic is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f4321",
   "metadata": {},
   "source": [
    "<img src=\"tp3/media/FF.png\" alt=\"Feedforward control system\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6f3d3",
   "metadata": {},
   "source": [
    "Here, the feedforward controller computes the appropriate control input to apply depending on the desired system output $y_{\\mathrm{des},k}$. It often uses knowledge of the system state $x_k$ and inverts the system dynamics to compute the control actions to be applied. \n",
    "\n",
    "For example, for the discrete-time system presented above at state $x_k$, the linear equation below can be solved (in a least-squares sense if not exactly solvable) for $u_k$ to compute the feedforward control action for trajectory following. We are assuming that $D = 0$ here.\n",
    "\n",
    "$y_{\\mathrm{des},k+1} = C(Ax_k + Bu_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d516c1",
   "metadata": {},
   "source": [
    "Pros of pure feedforward control: \n",
    "- FF control systems are simple.\n",
    "- Less likely to result in catastrophically unstable system.\n",
    "- May not require sensors and state estimation.\n",
    "- Can follow complex desired trajectories.\n",
    "\n",
    "Cons of pure feedforward control:\n",
    "- Rarely works alone in practice.\n",
    "- Sensitive to initial state estimation error and model errors.\n",
    "- Inverting system dynamics may not always be possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e1989",
   "metadata": {},
   "source": [
    "## Feedback control\n",
    "\n",
    "Feedforward control is often insufficient to track the desired trajectory in the presence of noise, model errors and disturbances. We need a negative feedback loop that measures the error between the desired trajectory and the real trajectory and uses it to reduce tracking errors. Negative feedback loops, being widely and frequently used, are nearly synonymous with the field of control.\n",
    "\n",
    "<img src=\"tp3/media/FB.png\" alt=\"Feedback control system\" width=\"500\"/>\n",
    "\n",
    "For LTI systems, a common form of negative feedback is the linear state feedback law \n",
    "\n",
    "$u = K (x_\\mathrm{des} - x)$.\n",
    "\n",
    "If the control task involves taking the system to the origin ($x_\\mathrm{des} = 0$),the closed-loop system is then described by the following discrete-time LTI system:\n",
    "\n",
    "$x_{k+1} = (A - BK)x_k$\n",
    "\n",
    "$y_k = Cx_k$\n",
    "\n",
    "For regulation tasks, when $x_\\mathrm{des}$ is fixed, it is always possible to redefine the origin of the system to formulate all regulation problems as taking the system to the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f632e38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "In practice, feedforward controllers and feedback controllers are both combined as shown below to leverage both their benefits.\n",
    "\n",
    "<img src=\"tp3/media/FF_FB.png\" alt=\"Feedback control system\" width=\"700\"/>\n",
    "\n",
    "Feedforward terms permit tracking complex trajectories using an imperfect system model while the feedback terms stabilize the system around the desired setpoint mitigating the negative effects of model inaccuracies and external disturbances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c57c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Linear Quadratic Regulator\n",
    "\n",
    "Linear Quadratic Regulator (LQR) is a widely used and popular controller that systematically results in a stable feedback controller and scales well to controlling high-dimensional systems (such as Humanoid robots). LQR computes control actions that minimizes the cost function, (assuming that the system is being stabilized around the origin):\n",
    "\n",
    "$J = \\sum_{t=0}^{\\infty} (x_t^T Q x_t + u_t^T R u_t)$,\n",
    "\n",
    "where $Q$ and $R$ are positive definite matrices (often just diagonal matrices), and chosen by the users.  The LQR controller is the optimal feedback gain that minimizes this cost function.  Choosing high-value of $Q$ relative to $R$ results in aggressive control behavior and faster state convergence to the origin. While this is often desirable, choosing $Q$ to be too high relative to $R$ can make the controller compute actions that exceed actuator limits and also makes it sensitive to process and measurement noise, which can result in a chattering behavior. Therefore an appropriate trade-off between control performance and robustness to noise and actuator limits needs to be made. The LQR controller can be computed using the following steps:\n",
    "\n",
    " 1. Solve the discrete-time Riccati equation for the system:\n",
    " \n",
    "    $ P = A^T P A - A^T P B (B^T P B + R)^{-1} B^T P A + Q $ \n",
    "\n",
    "2. Compute feedback gain\n",
    "\n",
    "    $K = (R + B^T P B)^{-1} B^T P A$\n",
    "\n",
    "3. The control law is then:\n",
    "    \n",
    "    $ u = -K x $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e2a6c",
   "metadata": {},
   "source": [
    "LQR (and linear control in general) is a useful tool even for controlling nonlinear systems. Nonlinear systems are often locally linearizable, using their first derivatives. The controller design is then performed for this linearized system and can be effective as long as the nonlinear system remains close to the linearization point.\n",
    "\n",
    "In this exercise, we will consider the nonlinear system cart-pole, linearized around the upright position. The state of the system is \n",
    "$x = \\begin{bmatrix} x \\\\ \\dot{x} \\\\ \\theta \\\\ \\dot{\\theta} \\end{bmatrix}$.\n",
    "\n",
    "he system dynamics and the linearization around the upright position can be found in \n",
    "https://courses.ece.ucsb.edu/ECE594/594D_W10Byl/hw/cartpole_eom.pdf. (Hint: Use equations 22 and 23.)\n",
    "\n",
    "Assume that $M = 1$, $m_p = 1$ and $L = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64818fd4",
   "metadata": {},
   "source": [
    "### Exercise 3.1\n",
    "\n",
    "Compute the LQR feedback gains for the cart-pole system linearized at the upright position. Stabilize the system at the upright position the LQR controller, starting from a state $x_0 = \\begin{bmatrix} 0, 0.1, 0, 0 \\end{bmatrix}^T$. Simulate the nonlinear system for 10 seconds and plot the state trajectories. The actuator forces $u \\in [-5, 5]$ N, verify if your controller satisfies these limits.\n",
    "\n",
    "(Hint: use scipy.linalg.solve_discrete_are to solve the Riccati equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from numpy.linalg import inv,norm,pinv,svd,eig\n",
    "from scipy.linalg import solve_discrete_are\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "g = 9.81\n",
    "M = 1\n",
    "m = 1\n",
    "l = 1\n",
    "\n",
    "K = []\n",
    "C = np.array([[0,1,0,0],[0,0,0,1]])\n",
    "## Code goes here to compute the feedback gains K \n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonlinear system, Forward Euler\n",
    "def nls_cartpole(x,u, Ts):\n",
    "    M = 1\n",
    "    m = 1\n",
    "    l = 1\n",
    "    xcdot = x[1]\n",
    "    thetadot = x[3]\n",
    "    xc = x[0]\n",
    "    theta = x[2]\n",
    "    s = np.sin(theta)\n",
    "    c = np.cos(theta)\n",
    "    u = np.clip(u, -5, 5)\n",
    "    xcddot = (-s*(m*l)*c*thetadot**2 + s*m*c*g + u)/(-m*c**2 + M + m)\n",
    "    thetaddot = (-s*(m*l)*c*thetadot**2 + s*g*(M+m) + u*c)/(l*(-m*c**2 + M + m))\n",
    "    xc = xc + Ts*xcdot\n",
    "    xcdot = xcdot + Ts*xcddot\n",
    "    theta = theta + Ts*thetadot\n",
    "    thetadot = thetadot + Ts*thetaddot\n",
    "    return np.hstack([xc,xcdot,theta,thetadot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsteps = 1000\n",
    "# simulate the system\n",
    "x0 = np.array([0,0,0.1,0])\n",
    "x_traj = []\n",
    "x_traj.append(x0)\n",
    "u_traj = []\n",
    "y_traj = []\n",
    "y_traj.append(C @ x0)\n",
    "for i in range(Nsteps):\n",
    "    u = -K @ x_traj[-1]\n",
    "    x_step = nls_cartpole(x_traj[-1],u,Ts)\n",
    "    x_traj.append(x_step)\n",
    "    y_traj.append(C @ x_step)\n",
    "    u_traj.append(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c098b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the simulated trajectory and the desired trajectory\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,Nsteps*Ts,Nsteps+1),[y[0] for y in y_traj])\n",
    "plt.plot(np.linspace(0,Nsteps*Ts,Nsteps+1),[y[1] for y in y_traj])\n",
    "plt.legend(['$\\\\theta$','$\\\\dot{\\\\theta}$'])\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('position (m)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the control input\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,Nsteps*Ts,Nsteps),u_traj)\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('control input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a5d90",
   "metadata": {},
   "source": [
    "## System stability\n",
    "\n",
    "Let us consider regulation problem, where the desired trajectory being tracked is a fixed set-point. Without loss of generality (why?) for regulation problems, we can assume that we want the system to reach the origin. A system \n",
    "\n",
    "$x_{k+1} = A x_k$,\n",
    "\n",
    "is said to be asymptotically stable if $\\lim_{k \\to \\infty} x_k = 0$. For an LTI system, checking for stability amounts to checking if the magnitude of all the eigenvalues of the matrix $A$ is strictly less than 1.0. Then the system is said to be strictly stable. If one eigenvalue has a magnitude equal to 1, the system is said to be marginally stable. If more than one eigenvalue has a magnitude equal to 1, the system may be unstable. If even one eigenvalue magnitude is strictly greater than one, the system is unstable.\n",
    "\n",
    "Note that a closed loop LTI system is given by\n",
    "\n",
    "$x_{k+1} = A_\\mathrm{cl} x_k$,\n",
    "\n",
    "where $A_\\mathrm{cl} = A - B K$. Therefore, stability of the closed-loop LTI systems is characterized using the eigenvalues of the matrix $A_\\mathrm{cl}$. \n",
    "\n",
    "It is important to characterize the stability of the feedback system, as it is a property that implies 'good behavior' of the closed-loop system, i.e. that it will not diverge or oscillate from the desired set-point.  Unstable systems can be dangerous in practice. \n",
    "\n",
    "\n",
    "### Exercise 3.2\n",
    "\n",
    "Compute the eigenvalues of the closed-loop LQR controller and the linearized system. Computed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5127e74",
   "metadata": {},
   "source": [
    "## Optimal Control of Nonlinear System with Constraints\n",
    "\n",
    "The previously discussed LQR controller works with a linearized system and does not take into account actuator limits. Optimal control is a framework that allows us to handle nonlinear systems and constraints in a systematic way. In this exercise, we will formulate and solve an optimal control problem for the nonlinear cart-pole system using multiple-shooting formulation via CasADi. \n",
    "\n",
    "CasADi is a symbolic framework for automatic differentiation and numerical optimization. It is widely used in robotics and control for solving optimal control problems. It provides a user-friendly interface for defining optimization problems and constraints, and it can efficiently compute gradients and Hessians using automatic differentiation.\n",
    "    \n",
    "To give a brief idea about CasADi's syntax, here is an example of a quadratic optimization problem with constraints. Consider the quadratic programmming problem below. For a brief overview of the multiple shooting framework, check out the nice blogpost on the CasADi website https://web.casadi.org/blog/ocp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb692e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import casadi as cs\n",
    "opti = cs.Opti()\n",
    "x = opti.variable(2)  # optimization variable\n",
    "Q = np.array([[1, 0], [0, 1]])\n",
    "opti.minimize(0.5 * x.T @ Q @ x)  # objective\n",
    "opti.subject_to(x[0] + x[1] == 1)  #\n",
    "opti.subject_to(x[0] >= 0)  # inequality\n",
    "opti.subject_to(-2 <= (x[1] <= 2))\n",
    "\n",
    "opti.solver('ipopt')  # set solver\n",
    "sol = opti.solve()  # solve the problem\n",
    "x_sol = sol.value(x)\n",
    "\n",
    "print('Optimal solution: x = ', x_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484fc701",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nonlinear system, Forward Euler\n",
    "def nls_casadi_cartpole(x,u, Ts):\n",
    "    M = 1\n",
    "    m = 1\n",
    "    l = 1\n",
    "    xcdot = x[1]\n",
    "    thetadot = x[3]\n",
    "    xc = x[0]\n",
    "    theta = x[2]\n",
    "    s = cs.sin(theta)\n",
    "    c = cs.cos(theta)\n",
    "    xcddot = (-s*(m*l)*c*thetadot**2 + s*m*c*g + u)/(-m*c**2 + M + m)\n",
    "    thetaddot = (-s*(m*l)*c*thetadot**2 + s*g*(M+m) + u*c)/(l*(-m*c**2 + M + m))\n",
    "    xc = xc + Ts*xcdot\n",
    "    xcdot = xcdot + Ts*xcddot\n",
    "    theta = theta + Ts*thetadot\n",
    "    thetadot = thetadot + Ts*thetaddot\n",
    "    return cs.vcat([xc,xcdot,theta,thetadot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe379a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Opti instance\n",
    "opti = cs.Opti()\n",
    "\n",
    "N = 200  # horizon length\n",
    "nx = 4  # number of states\n",
    "\n",
    "nu = 1  # number of inputs\n",
    "\n",
    "X = opti.variable(nx, N+1)  # state trajectory\n",
    "U = opti.variable(nu, N)    # control trajectory\n",
    "Ts = 0.02  # sampling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1947b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Q = np.diag([10, 1, 100, 1])  # state cost\n",
    "R = np.diag([0.1])            # input cost\n",
    "x0_val = np.array([0, 0, 0.1, 0])  # initial state\n",
    "\n",
    "x0 = opti.parameter(nx)  # initial state parameter\n",
    "opti.set_value(x0, x0_val)\n",
    "opti.subject_to(X[:, 0] == x0)  # initial condition constraint\n",
    "\n",
    "cost = 0\n",
    "\n",
    "## Your code here.\n",
    "# Impose the stagewise nonlinear dynamics constraints as equality constraint between timesteps and accumulate the linear quadratic cost over the horizon in the variable cost.\n",
    "\n",
    "#terminal constraint\n",
    "opti.subject_to(X[2:4, N] == np.array([0,0])) # require the pendulum to be upright at the end of the horizon\n",
    "\n",
    "opti.minimize(cost)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "opti.solver('ipopt', {\"expand\":True})  # set numerical solver\n",
    "\n",
    "sol = opti.solve()\n",
    "\n",
    "x_sol = sol.value(X)\n",
    "u_sol = sol.value(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot the optimal state trajectory\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol[0, :], label='$x$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol[1, :], label='$\\\\dot{x}$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol[2, :], label='$\\\\theta$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol[3, :], label='$\\\\dot{\\\\theta}$')\n",
    "plt.legend()\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('states')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b490d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the control signal\n",
    "plt.figure()\n",
    "plt.step(np.linspace(0,(N-1)*Ts,N),u_sol, where='post')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('control input')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381353be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Swing up\n",
    "\n",
    "new_x0_val = np.array([0, 0, 3, 0])\n",
    "opti.set_value(x0, new_x0_val)  # set new initial condition\n",
    "sol = opti.solve()\n",
    "x_sol_new_init = sol.value(X)\n",
    "u_sol_new_init = sol.value(U) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ac97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the control signal and the trajectory\n",
    "plt.figure()\n",
    "plt.step(np.linspace(0,(N-1)*Ts,N),u_sol_new_init, where='post')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('control input for swing up')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_new_init[0, :], label='$x$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_new_init[1, :], label='$\\\\dot{x}$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_new_init[2, :], label='$\\\\theta$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_new_init[3, :], label='$\\\\dot{\\\\theta}$')\n",
    "plt.legend()\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('states for swing up')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb534729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add actuator constraints to ensure that it stays within [-30, 30]\n",
    "\n",
    "### Your code here (should be one line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec96b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the actuator limits are challenging for the upright problem, may require many random initializations \n",
    "\n",
    "x_init = np.random.randn(nx, N+1)\n",
    "opti.set_initial(X, x_init)\n",
    "\n",
    "sol = opti.solve()\n",
    "x_sol_actuator_limited = sol.value(X)\n",
    "u_sol_actuator_limited = sol.value(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc18dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the values\n",
    "plt.figure()\n",
    "plt.step(np.linspace(0,(N-1)*Ts,N),u_sol_actuator_limited, where='post')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('control input with actuator limits')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b72a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot states\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_actuator_limited[0, :], label='$x$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_actuator_limited[1, :], label='$\\\\dot{x}$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_actuator_limited[2, :], label='$\\\\theta$')\n",
    "plt.plot(np.linspace(0,N*Ts,N+1),x_sol_actuator_limited[3, :], label='$\\\\dot{\\\\theta}$')\n",
    "plt.legend()\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('states with actuator limits')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robEx2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
